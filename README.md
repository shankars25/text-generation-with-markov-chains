# Text Generation using Markov Chains

###  Prodigy Infotech Internship Task – Task 3
**Author:** Shankar Sutar  
**Project:** Text Generation with Markov Chains  

---

##  Objective

To generate human-like text sequences by modeling word transitions using **Markov Chains**, a simple yet powerful probabilistic model for text generation.

---

##  Project Description

This project demonstrates how to create a **Markov Chain-based text generator** in Python.  
The program analyzes the input text, learns the probability of word transitions, and generates new sentences that mimic the style and structure of the original dataset.  

Unlike deep learning-based models such as GPT-2, this approach uses statistical relationships between words to produce coherent text.  

This project was developed as part of **Prodigy Infotech – Task 3** during the internship program.

---

## Key Features

-  Builds a **Markov Chain dictionary** from input text  
-  Learns word transition probabilities automatically  
- Generates new random sentences that resemble the training text  
-  Simple, lightweight, and easy to implement in Python  
-  Does **not** require machine learning frameworks like PyTorch or TensorFlow  

---

##  How to Run

1. Open the notebook **`Text_Generation_with_Markov_Chains.ipynb`** in **Google Colab** or any Python IDE.  
2. (Optional) Replace the default sample text in the code with your own dataset.  
3. Run all cells in order.  
4. The script will print the generated text based on your input dataset.  

---
